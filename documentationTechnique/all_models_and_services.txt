# backend/app/models/education.py

from sqlalchemy import Column, String, DateTime, Text
from sqlalchemy.orm import declarative_base
from datetime import datetime
import uuid
from app.db.base import Base 

class Education(Base):
    __tablename__ = "educations"

    id = Column(String, primary_key=True, default=lambda: str(uuid.uuid4()))
    degree = Column(String, nullable=False)  # ex: MSc in Engineering
    school = Column(String, nullable=True)
    start_date = Column(DateTime, nullable=True)
    end_date = Column(DateTime, nullable=True)
    location = Column(String, nullable=True)
    description = Column(Text, nullable=True)
    created_at = Column(DateTime, default=datetime.utcnow)
    updated_at = Column(DateTime, default=datetime.utcnow, onupdate=datetime.utcnow)
# backend/app/models/experience.py

from sqlalchemy import Column, String, DateTime, Text
from sqlalchemy.orm import declarative_base
from datetime import datetime
import uuid
from app.db.base import Base 

class Experience(Base):
    __tablename__ = "experiences"

    id = Column(String, primary_key=True, default=lambda: str(uuid.uuid4()))
    title = Column(String, nullable=False)  # ex: Full Stack Developer
    company = Column(String, nullable=True)
    start_date = Column(DateTime, nullable=True)
    end_date = Column(DateTime, nullable=True)
    location = Column(String, nullable=True)
    description = Column(Text, nullable=True)
    created_at = Column(DateTime, default=datetime.utcnow)
    updated_at = Column(DateTime, default=datetime.utcnow, onupdate=datetime.utcnow)
# backend/app/models/project.py

from sqlalchemy import Column, String, Integer, Boolean, DateTime
from sqlalchemy.orm import declarative_base
from datetime import datetime
from app.db.base import Base 

class Project(Base):
    __tablename__ = "projects"

    id = Column(Integer, primary_key=True, index=True)
    title = Column(String, nullable=False)
    description = Column(String, nullable=True)
    tech_stack = Column(String, nullable=True)
    github_url = Column(String, nullable=True)
    live_url = Column(String, nullable=True)
    image_url = Column(String, nullable=True)
    is_featured = Column(Boolean, default=False)
    created_at = Column(DateTime, default=datetime.utcnow)
    updated_at = Column(DateTime, default=datetime.utcnow, onupdate=datetime.utcnow)
# backend/app/models/skill.py

from sqlalchemy import Column, String, Integer, ForeignKey, DateTime
from sqlalchemy.orm import declarative_base, relationship
from datetime import datetime
import uuid
from app.db.base import Base 

class Skill(Base):
    __tablename__ = "skills"

    id = Column(String, primary_key=True, default=lambda: str(uuid.uuid4()))
    name = Column(String, unique=True, index=True, nullable=False)
    level = Column(Integer, nullable=True)  # Niveau de 1 à 5 par exemple
    category = Column(String, nullable=True)  # ex: "Programming", "Framework", "Tool"
    created_at = Column(DateTime, default=datetime.utcnow)
    updated_at = Column(DateTime, default=datetime.utcnow, onupdate=datetime.utcnow)
from sqlalchemy.orm import Session
from app.models.education import Education
from app.schemas.education import EducationCreate, EducationUpdate

def create_education(db: Session, edu: EducationCreate) -> Education:
    db_edu = Education(**edu.dict())
    db.add(db_edu)
    db.commit()
    db.refresh(db_edu)
    return db_edu

def get_educations(db: Session, skip: int = 0, limit: int = 100):
    return db.query(Education).offset(skip).limit(limit).all()

def get_education(db: Session, edu_id: str):
    return db.query(Education).filter(Education.id == edu_id).first()

def update_education(db: Session, edu_id: str, edu_update: EducationUpdate):
    db_edu = get_education(db, edu_id)
    if not db_edu:
        return None
    for key, value in edu_update.dict(exclude_unset=True).items():
        setattr(db_edu, key, value)
    db.commit()
    db.refresh(db_edu)
    return db_edu

def delete_education(db: Session, edu_id: str):
    db_edu = get_education(db, edu_id)
    if not db_edu:
        return None
    db.delete(db_edu)
    db.commit()
    return db_edu
from sqlalchemy.orm import Session
from app.models.experience import Experience
from app.schemas.experience import ExperienceCreate, ExperienceUpdate

def create_experience(db: Session, exp: ExperienceCreate) -> Experience:
    db_exp = Experience(**exp.dict())
    db.add(db_exp)
    db.commit()
    db.refresh(db_exp)
    return db_exp

def get_experiences(db: Session, skip: int = 0, limit: int = 100):
    return db.query(Experience).offset(skip).limit(limit).all()

def get_experience(db: Session, exp_id: str):
    return db.query(Experience).filter(Experience.id == exp_id).first()

def update_experience(db: Session, exp_id: str, exp_update: ExperienceUpdate):
    db_exp = get_experience(db, exp_id)
    if not db_exp:
        return None
    for key, value in exp_update.dict(exclude_unset=True).items():
        setattr(db_exp, key, value)
    db.commit()
    db.refresh(db_exp)
    return db_exp

def delete_experience(db: Session, exp_id: str):
    db_exp = get_experience(db, exp_id)
    if not db_exp:
        return None
    db.delete(db_exp)
    db.commit()
    return db_exp
# backend/app/crud/project.py


from sqlalchemy.orm import Session
from app.models.project import Project
from app.schemas.project import ProjectCreate, ProjectUpdate

def get_project(db: Session, project_id: int):
    return db.query(Project).filter(Project.id == project_id).first()

def get_projects(db: Session, skip: int = 0, limit: int = 100):
    return db.query(Project).offset(skip).limit(limit).all()

def create_project(db: Session, project: ProjectCreate):
    db_project = Project(**project.model_dump())
    db.add(db_project)
    db.commit()
    db.refresh(db_project)
    return db_project

def update_project(db: Session, project_id: int, project: ProjectUpdate):
    db_project = get_project(db, project_id)
    if not db_project:
        return None
    for field, value in project.model_dump(exclude_unset=True).items():
        setattr(db_project, field, value)
    db.commit()
    db.refresh(db_project)
    return db_project

def delete_project(db: Session, project_id: int):
    db_project = get_project(db, project_id)
    if not db_project:
        return None
    db.delete(db_project)
    db.commit()
    return db_project
from sqlalchemy.orm import Session
from app.models.skill import Skill
from app.schemas.skill import SkillCreate, SkillUpdate

def create_skill(db: Session, skill: SkillCreate) -> Skill:
    db_skill = Skill(**skill.dict())
    db.add(db_skill)
    db.commit()
    db.refresh(db_skill)
    return db_skill

def get_skills(db: Session, skip: int = 0, limit: int = 100):
    return db.query(Skill).offset(skip).limit(limit).all()

def get_skill(db: Session, skill_id: str):
    return db.query(Skill).filter(Skill.id == skill_id).first()

def update_skill(db: Session, skill_id: str, skill_update: SkillUpdate):
    db_skill = get_skill(db, skill_id)
    if not db_skill:
        return None
    for key, value in skill_update.dict(exclude_unset=True).items():
        setattr(db_skill, key, value)
    db.commit()
    db.refresh(db_skill)
    return db_skill

def delete_skill(db: Session, skill_id: str):
    db_skill = get_skill(db, skill_id)
    if not db_skill:
        return None
    db.delete(db_skill)
    db.commit()
    return db_skill
# backend/app/chatbot/core/embeddings_service.py
import logging
from typing import List, Optional
from datetime import datetime
import numpy as np
from sqlalchemy.orm import Session

from sentence_transformers import SentenceTransformer

from app.chatbot.models.embedding import Embedding
from app.chatbot.crud.embedding import create_embedding_record  # nouveau wrapper

import faiss

logger = logging.getLogger(__name__)

class EmbeddingsService:
    """
    Service pour créer et gérer des embeddings :
    - Création via SentenceTransformers
    - Stockage en BDD
    - Indexation dans FAISS pour recherche rapide
    """
    def __init__(self, model_name: str = 'all-MiniLM-L6-v2'):
        self.model = SentenceTransformer(model_name)
        self.embedding_dim = self.model.get_sentence_embedding_dimension()
        self.index = faiss.IndexFlatL2(self.embedding_dim)
        self.embeddings_map = {}  # mapping id -> vector

    def _compute_embedding(self, text: str) -> List[float]:
        """Génère un embedding localement via SentenceTransformers"""
        vector = self.model.encode([text])[0]
        return vector.tolist()

    def add_embedding(
        self,
        db: Session,
        text: str,
        source: str,
        reference_id: Optional[str] = None
    ) -> str:
        """Génère un embedding, le stocke en BDD et dans FAISS"""
        vector = self._compute_embedding(text)
        embedding_id = reference_id or str(datetime.utcnow().timestamp()).replace('.', '')

        # Stockage en BDD via le wrapper
        embedding_record = Embedding(
            id=embedding_id,
            vector=vector,
            content=text,
            source=source,
            reference_id=reference_id,
            created_at=datetime.utcnow(),
            updated_at=datetime.utcnow()
        )
        create_embedding_record(db, embedding_record)  # <- corrige l'appel

        # Ajout à FAISS
        vector_np = np.array([vector], dtype='float32')
        self.index.add(vector_np)
        self.embeddings_map[embedding_id] = vector_np

        logger.info(f"Embedding ajouté: {embedding_id} source={source}")
        return embedding_id

    def search(self, query: str, top_k: int = 5) -> List[str]:
        """Recherche les embeddings les plus proches dans FAISS et retourne leurs ids"""
        query_vector = np.array([self._compute_embedding(query)], dtype='float32')
        distances, indices = self.index.search(query_vector, top_k)
        results = []
        for idx in indices[0]:
            if idx < len(self.embeddings_map):
                emb_id = list(self.embeddings_map.keys())[idx]
                results.append(emb_id)
        return results

    def build_index_from_db(self, db: Session):
        """Reconstruit l'index FAISS à partir de la BDD (utile au démarrage)"""
        embeddings = db.query(Embedding).all()
        for emb in embeddings:
            vector_np = np.array([emb.vector], dtype='float32')
            self.index.add(vector_np)
            self.embeddings_map[emb.id] = vector_np
        logger.info(f"Index FAISS reconstruit avec {len(embeddings)} embeddings")
import faiss
import numpy as np
import logging
from typing import List, Optional
from sqlalchemy.orm import Session

from app.chatbot.models.embedding import Embedding

logger = logging.getLogger(__name__)

class FAISSIndex:
    def __init__(self, embedding_dim: Optional[int] = None, index_path: Optional[str] = None):
        """
        Gestion d'un index FAISS avec persistance optionnelle.
        """
        self.embedding_dim = embedding_dim
        if self.embedding_dim is None:
            raise ValueError("embedding_dim doit être fourni pour initialiser FAISSIndex")
        
        self.index = faiss.IndexFlatL2(self.embedding_dim)
        self.index_path = index_path
        self.embeddings_map: dict[str, np.ndarray] = {}

        if index_path:
            self.load_index()

    def add_vector(self, emb_id: str, vector: List[float]):
        vector_np = np.array([vector], dtype="float32")
        self.index.add(vector_np)
        self.embeddings_map[emb_id] = vector_np
        logger.debug(f"Vector ajouté à FAISS: {emb_id}")

    def search(self, query_vector: List[float], top_k: int = 5) -> List[str]:
        if self.index.ntotal == 0:
            logger.warning("Index FAISS vide")
            return []

        query_np = np.array([query_vector], dtype="float32")
        distances, indices = self.index.search(query_np, top_k)
        all_keys = list(self.embeddings_map.keys())
        results = []
        for idx in indices[0]:
            if idx < len(all_keys):
                results.append(all_keys[idx])
        return results

    def build_index_from_db(self, db: Session):
        embeddings = db.query(Embedding).all()
        for emb in embeddings:
            self.add_vector(emb.id, emb.vector)
        logger.info(f"Index FAISS reconstruit avec {len(embeddings)} embeddings")

    def save_index(self):
        if self.index_path:
            faiss.write_index(self.index, self.index_path)
            logger.info(f"Index FAISS sauvegardé sur {self.index_path}")

    def load_index(self):
        try:
            self.index = faiss.read_index(self.index_path)
            logger.info(f"Index FAISS chargé depuis {self.index_path}")
        except Exception:
            logger.warning(f"Impossible de charger l'index depuis {self.index_path}, création d'un index vide")
            self.index = faiss.IndexFlatL2(self.embedding_dim)

# backend/app/db/session.py

from sqlalchemy import create_engine
from sqlalchemy.orm import sessionmaker
import os

DATABASE_URL = os.getenv("DATABASE_URL", "postgresql+psycopg2://postgres:postgres@localhost:5432/portfolio_db")

engine = create_engine(
    DATABASE_URL,
    echo=True,  # affiche les requêtes SQL (pratique en dev)
)

SessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)

# Dependency pour FastAPI
def get_db():
    db = SessionLocal()
    try:
        yield db
    finally:
        db.close()
